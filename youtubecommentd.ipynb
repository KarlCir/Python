{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your API key here \n",
    "api_key = 'YOUR API KEY'\n",
    "\n",
    "# Build the service object\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Replace 'VIDEO_ID' with the ID of the video you want comments from\n",
    "video_id = 'pEskP0ulPlA'\n",
    "\n",
    "# Request the comments\n",
    "comments = youtube.commentThreads().list(\n",
    "    part='snippet',\n",
    "    videoId=video_id,\n",
    "    maxResults=100,  # Limit to 100 comments\n",
    "    textFormat='plainText'\n",
    ").execute()\n",
    "\n",
    "# List to hold the comments\n",
    "comments_list = []\n",
    "\n",
    "# Iterate through the comments and extract the required info\n",
    "for item in comments['items']:\n",
    "    comment = item['snippet']['topLevelComment']['snippet']\n",
    "    comments_list.append([comment['authorDisplayName'], comment['publishedAt'], comment['textDisplay']])\n",
    "\n",
    "# Create a DataFrame\n",
    "comments_df = pd.DataFrame(comments_list, columns=['User', 'Date', 'Comment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment\n",
    "def get_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    probs = softmax(outputs.logits, dim=1)\n",
    "    sentiment = torch.argmax(probs, dim=1).numpy()[0]  # 0: Negative, 1: Neutral, 2: Positive\n",
    "    return ['-1', '0', '1'][sentiment]\n",
    "\n",
    "# Apply sentiment analysis on the 'Comment' column\n",
    "comments_df['Sentiment'] = comments_df['Comment'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.to_csv('youtube_comments.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
